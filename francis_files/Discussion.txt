Discussion (8)
Implications of the experimental results. (4)
Is the original paper reproducible? And if it wasnâ€™t, what factors made it irreproducible?
What was easy? (1)
What was difficult? (1)
Recommendations to the original authors or others who work in this area for improving reproducibility (2)

There are several implications of the experimental results. Using two signals, ECG and SpO2, the detection performance of sleep apnea is comparable to the full polysomnography signals testing. This is significant because ECG and SpO2 are easier to collect with commercial devices compared to the other polysomnography signals. Because of the easier access, this suggests that the easier tests can be done at home and not needed to be collected in a sleep lab. The transformer-based model performed better than the previous models such as CNN, SE-MSCNN, CNN+LSTM, and Hybrid across both NCH and CHAT data. The multi-modal approach is effective because it incorporates information from the different signal types. Also the transformer architecture is more flexible in handling the huge variability in signal quality. The model has a consistently strong performance among the different pediatric age ranges. Currently at-home testing is only suggested to be effective in adults and older children, so this research suggest that this approach can be done throughout the entire pediatric population. The results also show that the model sustains its performance even with added noise. This could imply that the testing can be used even with commercial products that usually have lower qualities of signals.

The original paper wasn't fully reproducible. The difficult factor that made it irreproducible was mainly the raw data and the models used. The raw data uses several hundreds of EDFs which is each around 500mb - 1.6gb in size. This caused several issues in the preprocessing step and we had to generate our own preprocessed data to continue with other parts of the research. We were also not able to reproduce the model the researchers used fully. Although we tried implementing the model they described, the results we gathered was not in line with what the researchers collected. Training and evaluation was the easier parts to reproduce as they were explained in more detail by the researchers in terms of both calculation and in their code.

A recommendation to the authors could be creating a readme file with a detailed setup instruction that includes dependencies, hardware requirements and expected runtime. This will help future researchers of the topic to save time in debugging and especially wrangling the raw data. Another recommendation is creating a configuration file instead of hard-coded paths in their GitHub. They can also include anonymized sample data themselves for testing and validation by future researchers. For future researchers a recommendation would be reporting the performance of the models across different demographic groups like gender. They can also use container technologies like Docker to make sure the research is reproducible in different environments.